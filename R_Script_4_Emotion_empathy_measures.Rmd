---
title: "EK / EM report measures"
output: 
  rmdformats::material:
    highlight: kate
    css: web_style.css
    thumbnails: false
    lightbox: true
    gallery: true
    cards: true
    self_contained: no
    number_sections: no
    code_folding: hide
    fig_caption: yes
---

<!-- Set up workspace -->

```{r setup, include = FALSE, message = FALSE, warning = FALSE}

# Set general settings for Markdown file 
  options(max.print="75")

  knitr::opts_chunk$set(echo=TRUE,
  	             #cache=TRUE,
                 prompt=FALSE,
                 tidy=TRUE,
                 comment=NA,
                 message=FALSE,
                 warning=FALSE,
                 results = FALSE,
  	             fig.align="center",
  	             fig.width = 6, fig.height = 4)
  knitr::opts_knit$set(width=75)

# Swipe environment
  rm(list=ls())
  
# Load packages
  library(apaTables)
  library(corrplot)
  library(cowplot)
  library(dplyr)
  library(eeptools)
  library(EnvStats)
  library(ez)
  library(ggplot2)
  library(ggpubr)
  library(ggstatsplot)
  library(gridGraphics)
  library(gvlma)
  library(Hmisc)
  library(kableExtra)
  library(knitr)
  library(lme4)
  library(lmerTest)
  library(MASS)
  library(miceadds)
  library(multcomp)
  library(pander)
  library(psych)
  library(reshape2)
  library(Rmisc)
  library(sjPlot)
  library(sjmisc)
  library(sjlabelled)
  library(stringr)
  library(table1)
  library(tidyverse)

# Raincloud plot function   
  source("./functions/geom_flat_violin.R")
    
# Load overdispersion function
  overdisp_fun = function(model) {
      rdf = df.residual(model)
      rp = residuals(model,type="pearson")
      Pearson.chisq = sum(rp^2)
      prat = Pearson.chisq/rdf
      pval = pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
      c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
  }
  
# Load correlation table function (https://stefaneng.github.io/apa_correlation_table/)
 apply_if <- function(mat, p, f) {
  # Fill NA with FALSE
  p[is.na(p)] <- FALSE
  mat[p] <- f(mat[p])
  mat
}


apaCorr <- function(mat, corrtype = "spearman") {
  matCorr <- mat
  if (class(matCorr) != "rcorr") {
    matCorr <- rcorr(mat, type = corrtype)
  }

  # Add one star for each p < 0.05, 0.01, 0.001
  stars <- apply_if(round(matCorr$r, 2), matCorr$P < 0.05, function(x) paste0(x, "*"))
  stars <- apply_if(stars, matCorr$P < 0.01, function(x) paste0(x, "**"))
  stars <- apply_if(stars, matCorr$P < 0.001, function(x) paste0(x, "***"))
  # Put - on diagonal and blank on upper diagonal
  stars[upper.tri(stars, diag = T)] <- "-"
  stars[upper.tri(stars, diag = F)] <- ""
  n <- length(stars[1,])
  colnames(stars) <- 1:n
  # Remove _ and convert to title case
  row.names(stars) <- tools::toTitleCase(sapply(row.names(stars), gsub, pattern="_", replacement = " "))
  # Add index number to row names
  row.names(stars) <- paste(paste0(1:n,"."), row.names(stars))
  stars
}
  
# Round to 2 digits   
  options(digits=2)
  
# Disable scientific notation in R
  options(scipen = 999)
  
# Set figure theme  
  theme_SN = theme(axis.title.y = element_text(size = 15, margin = margin(t = 0, r = 20, b = 0, l = 0)),
          panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(),
          panel.grid.major.y = element_line(colour = "black", linetype = "dotted", size=0.6),
          panel.grid.minor.y = element_blank(),
          panel.background = element_rect(colour = "black", size = 0.5),
          text=element_text(size = 15),
          legend.position = "none")  
  
# Set figure color palettes
  emotion_col = c("#99bada","#3375b5","#003162")
  
# Mean-center function
  center_scale <- function(x) {
    scale(x, scale = FALSE)}  
  
# Round p-values   
  reportP = function(pValue){
    if (pValue < 0.001){
      result = "*p* < 0.001"
    } else {
      result = sprintf("*p* = %.2f", pValue) # inserts a float into a string and simultaneously do rounding
    }
    return(result)
  }  
  
# Beta values
  reportbe = function(pValue){
    if (0 <= pValue & pValue <= 0.01 ){
      result = "< 0.01"
    } 
    else if (pValue < 0){
      result = sprintf("= %.2f", pValue)
    }
    else {
      result = sprintf("= %.2f", pValue) # inserts a float into a string and simultaneously do rounding
    }
    return(result)
  }  
  
# CI values
  reportci = function(pValue){
    if (0 <= pValue & pValue <= 0.01 ){
      result = "< 0.01"
    } 
    else if (pValue < 0){
      result = sprintf("%.2f", pValue)
    }
    else {
      result = sprintf("%.2f", pValue) # inserts a float into a string and simultaneously do rounding
    }
    return(result)
  }    
  
```

<!-- Load and prepare data sets -->

```{r load_data, include = FALSE}

# Load data
  load.Rdata(filename="./data/EMT_data.Rdata", "EMT")
  load.Rdata(filename="./data/ERP_data.Rdata", "ERPs")
  load.Rdata(filename="./data/qn_data.Rdata", "qn_data")

```

# Emotion Matching Task (EMT)

We employed an emotion matching task (EMT) to assess children's emotion knowledge. Children saw two faces with the same identity but different facial expression. Both faces were presented at the same time. While the faces were on screen, the children heard an audio lay-over of one of the emotion words (happy, angry or neutral). The children had to indicate with a button press which face matched the audio lay-over. We measured reaction times and accuracy.

We excluded:

  + Reaction times < 250 ms or >  7s
  + Incorrect responses

For the EMT we included a treatment contrast for facial expressions (`emotional [average of happy/angry] vs. neutral faces (Emo_Neu)`, `happy vs. angry faces (Hap_Ang)`) as fixed factor. We calculated a GLMM for accuracy rates and an LMM for RTs. Working memory (`WM_scal`) was entered as a scaled covariate in all (G)LMM analyses to control for cognitive task demands. 

The random effects structure included random intercepts for participants (`(1|ID)`) and stimulus (`(1|Stim_Type)`). Assumptions for multiple regression were checked for all models (normality of the residuals, linearity, multicollinearity, homoscedasticity). 

We expected the highest accuracy rates for happy faces and fastest reaction times for pairings where happy faces were involved.

<br>

#### **Descriptives**

Accuracy rates (left side) and reaction times (right side) of the emotion matching task (EMT). Error bars indicate standard errors (SE).

```{r EMT_bar_plots, results = "asis"}

# Select RT inspected criteria / correct trials

  EMT_Acc_Plot = subset(EMT, Answer == 1 & Exclude_smaller_250ms == FALSE)

# Create factor, define neutral as baseline
  EMT_Acc_Plot$emotion = factor(EMT_Acc_Plot$emotion, levels=c("neutral","happy","angry"))

# Get accuracy for novel and repeated condition 
  acc_all = data.frame(xtabs(~ID+emotion, EMT_Acc_Plot)) 

# Recode to accuracy in percent
  acc_all$Freq = (acc_all$Freq/24)*100

# Calculate descriptives on accuracy
  stats_acc_all = summarySEwithin(acc_all, measurevar="Freq", withinvars=c("emotion"), idvar = "ID")

# Plot accuracy
  EMT_Acc_bar = ggplot(stats_acc_all, aes(x=emotion, y=Freq, fill = emotion)) + 
    geom_bar(position=position_dodge(), stat="identity",colour="black", size=0.4, width=0.6) +
    geom_errorbar(aes(ymin=Freq-se, ymax=Freq+se), size=0.4, width=0.2, position=position_dodge(.9)) +
    labs (x= "", y = "Accuracy [%]") +
    coord_cartesian(ylim = c(0, 80)) +
    scale_y_continuous(breaks=seq(0,100,20))+
    scale_fill_manual(values=c("#ababab","#ababab","#ababab"))+
    theme_bw()+
    theme_SN

# Only examine clean data / correct responses
  EMT_RT_Plot = subset(EMT, Exclude_smaller_250ms == FALSE & Answer == 1)

# Create factor, define neutral as baseline
  EMT_RT_Plot$emotion = factor(EMT_RT_Plot$emotion, levels=c("neutral","happy","angry"))

# Get accuracy for novel and repeated condition 
  RT_all = aggregate(EMT_RT_Plot$RT_in_ms,
               list(ID = EMT_RT_Plot$ID, emotion = EMT_RT_Plot$emotion), mean)
  
# Set ID as factor  
  RT_all$ID = as.factor(RT_all$ID)  

# Calculate descriptives on RT
  stats_RT_all = summarySEwithin(RT_all, measurevar="x", withinvars=c("emotion"), idvar = "ID")

# Plot RTs
  EMT_RT_bar = ggplot(stats_RT_all, aes(x=emotion, y=x, fill = emotion)) + 
    geom_bar(position=position_dodge(), stat="identity",colour="black", size=0.4, width=0.6)+
    geom_errorbar(aes(ymin=x-se, ymax=x+se), size=0.4, width=0.2, position=position_dodge(.9)) +
    labs (x= "", y = "RT [ms]") +
    coord_cartesian(ylim = c(0, 5000)) +
    scale_y_continuous(breaks=seq(0,5000,1000))+
    scale_fill_manual(values=c("#ababab","#ababab","#ababab"))+
    theme_bw()+
    theme_SN
  
# Combine plots
   fig_EMT = cowplot::plot_grid(
    EMT_Acc_bar, EMT_RT_bar,
    align = 'vh',
    hjust = -1,
    nrow = 1)
   
   fig_EMT
   
```

#### **Model specification** {.tabset .tabset-pills}

##### GLMM: Random effect structure

We fitted single-trial data to the following model:

```{r EMT_Acc_GLMM_res}

# RT cleaning criteria
  EMT_Acc = subset(EMT, Exclude_smaller_250ms == FALSE)

# Factor random effects
  EMT_Acc$ID = as.factor(EMT_Acc$ID)
  EMT_Acc$Stim_Type = as.factor(EMT_Acc$Stim_Type)

# Create factor, define neutral as baseline
  EMT_Acc$emotion = factor(EMT_Acc$emotion)
  contrasts(EMT_Acc$emotion) = contr.treatment(3,  base = 3)

# A = angry, N = neutral, H = happy
  HvsA = c(0.5,-0.5,0) # compare: happy vs. angry
  EvsN = c(-0.25,-0.25,0.5) # compare happy/angry to neutral
  contrasts(EMT_Acc$emotion) = cbind(EvsN,HvsA)
  
   mod_EMT_Acc.glmm = glmer(Answer ~ emotion + scale(WM) +
                             (1 |ID) +
                             (1 |Stim_Type),
                           data = EMT_Acc,control=glmerControl(calc.derivs = FALSE),
                           family = binomial)

```

 ``r format(formula(mod_EMT_Acc.glmm))``

---

##### GLMM: Overdispersion

If the p-value is < 0.05, data would be overdispersed. Here p > 0.05. Hence, overdispersion is not a problem.

```{r EMT_Acc_GLMM_overd, results = TRUE}

# Assumption check: Appropriate estimation of variance
  overdisp_fun(mod_EMT_Acc.glmm)

```

---

##### LMM: Random effect structure

We fitted single-trial data to the following model:

```{r EMT_RT_LMM_build_mod}

# RT criteria / correct responses
  EMT_RT = subset(EMT, Answer == 1 & Exclude_smaller_250ms == FALSE)

# Factor random effects
  EMT_RT$ID = as.factor(EMT_RT$ID)
  EMT_RT$Stim_Type = as.factor(EMT_RT$Stim_Type)

# Create factor, define neutral as baseline
  EMT_RT$emotion = factor(EMT_RT$emotion)
  contrasts(EMT_RT$emotion) = contr.treatment(3,  base = 3)

# A = angry, N = neutral, H = happy
  HvsA = c(0.5,-0.5,0) # compare: happy vs. angry
  EvsN = c(-0.25,-0.25,0.5) # compare happy/angry to neutral
  contrasts(EMT_RT$emotion) = cbind(EvsN,HvsA)
  
# Build model
  mod_EMT_RT.lmer = lmer(log(RT_in_ms) ~
                            emotion + scale(WM) +
                            (1 |ID) +
                            (1 |Stim_Type),
                          data = EMT_RT,
                          control=lmerControl(calc.derivs = FALSE))
  
  tab_model(mod_EMT_RT.lmer)
  
```

 ``r format(formula(mod_EMT_RT.lmer))``


---

##### LMM: Normality of residuals

RTs were log-transformed (determined using the Box-Cox procedure) to meet the assumption of normally distributed residuals.

```{r EMT_RT_LMM_res, fig.width = 6, fig.asp = .62}

# Visualize normality assumption of residuals (without log transform)
  mod_RT_lmm_no_log = lm(RT_in_ms ~ emotion, data=EMT_RT)
  res.mod_RT_lmm_no_log = residuals(mod_RT_lmm_no_log)

  par(mfrow=c(1,2))


  qqpl_RT_lmm_no_log = qqPlot(res.mod_RT_lmm_no_log, main="QQplot before transformation")
  norm_RT_lmm_no_log = plot(density(res.mod_RT_lmm_no_log), main="Density plot before transformation")
  par(mfrow=c(1,1))

# Check which transformation of DV is suitable

# Calculate box-cox plot
  mod_RT_targ = lm(RT_in_ms ~ emotion, data=EMT_RT)
  boxcox(mod_RT_targ)

# Visualize normality assumption of residuals (with log transform)
  mod_RT_lmm_log = lm(log(RT_in_ms) ~ emotion, data=EMT_RT)
  res.mod_RT_lmm_log = residuals(mod_RT_lmm_log)

  par(mfrow=c(1,2))
  qqpl_RT_lmm_log = qqPlot(res.mod_RT_lmm_log, main="QQplot after transformation")
  norm_RT_lmm_log = plot(density(res.mod_RT_lmm_log), main="Density plot after transformation")
  par(mfrow=c(1,1))

```
---

##### LMM: Homoscedasticity

```{r EMT_RT_LMM_homosk, fig.width = 5, fig.asp = .62}

# Check homoscedasticity
  plot(fitted(mod_EMT_RT.lmer), residuals(mod_EMT_RT.lmer))
  abline(0, 0)

```

---

#### **Results**

```{r EMT_post_hoc_calc}

# Calculate post-hoc tests

  mod_EMT_RT.lmer2 = lmer(log(RT_in_ms) ~
                            emotion + scale(WM) +
                            (1 |ID) +
                            (1 |Stim_Type),
                          data = EMT_RT,
                          control=lmerControl(calc.derivs = FALSE))
 
  
# Choose contrasts of interest / add fdr-correction
  EMT_RT_posthoc =  summary(glht(mod_EMT_RT.lmer2, linfct=mcp(emotion = c(
                                                        "angry - neutral = 0",
                                                        "happy - neutral = 0")), test = adjusted(type = "fdr")))
 
# Get ready for presentation in RMarkdown
  tab1 = merge(as.data.frame(EMT_RT_posthoc$test$coefficients),as.data.frame(EMT_RT_posthoc$test$sigma),by=0)
  tab2 = as.data.frame(EMT_RT_posthoc$test$pvalues)
  rownames(tab2) = rownames(as.data.frame(EMT_RT_posthoc$test$tstat))
  tab2 = merge(as.data.frame(EMT_RT_posthoc$test$tstat),tab2,by=0)
  EMT_RT_posthoc = merge(tab1,tab2,by='Row.names')
  colnames(EMT_RT_posthoc) = c("Contrast","Est.","Std. Error", "z value", "p value")

```

There were no accuracy differences between emotional vs. neutral expressions ($\beta$ `r reportbe(coef(summary(mod_EMT_Acc.glmm))[2,1])`, `r reportP(coef(summary(mod_EMT_Acc.glmm))[2,4])`, *OR* `r reportbe(exp(coef(summary(mod_EMT_Acc.glmm))[2,1]))` [95% CI: `r reportci((exp(coef(summary(mod_EMT_Acc.glmm))[2,1]) + qnorm(c(0.05,0.5,0.95)) * exp(coef(summary(mod_EMT_Acc.glmm))[2,1]))[1])`, `r reportci((exp(coef(summary(mod_EMT_Acc.glmm))[2,1]) + qnorm(c(0.05,0.5,0.95)) * exp(coef(summary(mod_EMT_Acc.glmm))[2,1]))[3])`]), nor happy vs. angry expressions ($\beta$ `r reportbe(coef(summary(mod_EMT_Acc.glmm))[3,1])`, `r reportP(coef(summary(mod_EMT_Acc.glmm))[3,4])`, *OR* `r reportbe(exp(coef(summary(mod_EMT_Acc.glmm))[3,1]))` [95% CI: `r reportci((exp(coef(summary(mod_EMT_Acc.glmm))[3,1]) + qnorm(c(0.05,0.5,0.95)) * exp(coef(summary(mod_EMT_Acc.glmm))[3,1]))[1])`, `r reportci((exp(coef(summary(mod_EMT_Acc.glmm))[3,1]) + qnorm(c(0.05,0.5,0.95)) * exp(coef(summary(mod_EMT_Acc.glmm))[3,1]))[3])`]). 
  For reaction times, the emotional vs. neutral expression contrast was significant ($\beta$ `r reportbe(coef(summary(mod_EMT_RT.lmer))[2,1])`, `r reportP(coef(summary(mod_EMT_RT.lmer))[2,5])`). Post-hoc tests indicated that happy expressions were detected faster than neutral expressions(`r reportP(EMT_RT_posthoc[2,5])`; angry vs neutral: `r reportP(EMT_RT_posthoc[1,5])`). The happy vs. angry contrast yielded no significant results ($\beta$ `r reportbe(coef(summary(mod_EMT_RT.lmer))[3,1])`, `r reportP(coef(summary(mod_EMT_RT.lmer))[3,5])`).

<div align="center">

```{r EMT_result_table, results = TRUE}

# Define labels
  labels = c("Emotional vs. Neutral", "Happy vs. Angry", "Working Memory")

# Show results
  tab_model(mod_EMT_Acc.glmm, mod_EMT_RT.lmer,
          pred.labels=labels, show.ci = FALSE,
          show.se = TRUE, string.se = "SE",
          show.stat = TRUE, string.stat = "t",
          show.re.var = TRUE, show.obs = FALSE,
          show.intercept = FALSE,
          emph.p = TRUE, dv.labels=c("Accuracy","Reaction time") , show.icc = TRUE)

```

</div>

<br>

*Note:* p-values for the fixed effects calculated using Wald-statistics approximation, uncorrected. *SE*: standard error; *t*: test statistic coefficient; *p*: p-value; *σ2*: within-group variance; *τ00*: between-group variance; *ICC*: interclass correlation (ratio of between-cluster variance to total variance); *N*: number of random effects.

<br>

**Post-hoc tests: Reaction time contrast emotional vs. neutral:**

```{r EMT_post_hoc, results = "asis"}

# Create table
  kable(EMT_RT_posthoc) %>% 
    kable_styling(bootstrap_options = c("hover"), font_size = 14,fixed_thead = T)
```


```{r save_models, include = FALSE, eval = FALSE}

# Save data set in RData format
  save(mod_EMT_Acc.glmm, file = "./data/mod_EMT_Acc.glmm4.RData")
  save(mod_EMT_RT.lmer, file = "./data/mod_EMT_RT.lmer5.RData")
  save(EMT_RT_posthoc, file = "./data/EMT_RT_posthoc.RData")

```

# ERP association with empathy / emotion knowledge

```{r Correlations_Prep}

## Re-do this section for accuracy data --> use ERPs dataset for accuracy calculation

## Select data
  load.Rdata(filename="./data/ERP_data.Rdata", "ERP_data")
  ERPs_sel = subset(ERP_data, Exclude_smaller_250ms == FALSE & Response == 1)
  
# Face 2: P1 repeated happy
  ERP_hap_Face2_rep = subset(ERPs_sel, Condition == 4)
  Corr_data = data.frame(tapply(ERP_hap_Face2_rep$mean_ROI_P1,ERP_hap_Face2_rep$ID, mean))
  names(Corr_data)[1] = "P1_hap_rep"
  
# Face 2: P1 novel happy  
  ERP_hap_Face2_nov = subset(ERPs_sel, Condition == 7)
  Corr_data$P1_hap_nov = tapply(ERP_hap_Face2_nov$mean_ROI_P1,ERP_hap_Face2_nov$ID, mean)  
  
# Face 2: P1 novel angry 
  ERP_ang_Face2_nov = subset(ERPs_sel, Condition == 9)
  Corr_data$P1_ang_nov = tapply(ERP_ang_Face2_nov$mean_ROI_P1,ERP_ang_Face2_nov$ID, mean)

  Corr_data = Corr_data[-c(4),]

# EMT
    
# Calculate difference scores
  Corr_data$P1_F2_Nov_Rep_Hap = Corr_data$P1_hap_nov-Corr_data$P1_hap_rep
  Corr_data$P1_F2_Nov_Hap_Ang = Corr_data$P1_hap_nov-Corr_data$P1_ang_nov
  
# Order questionnaire data by ID  
  qn_data = qn_data[order(qn_data$ID),]

# Integrate questionnare data   
  Corr_data$EMK_EK_P = qn_data$EMK_EK_P
  Corr_data$EMK_EM_P = qn_data$EMK_EM_P
  Corr_data$EMK_EK_Ch = qn_data$EMK_EK_Ch
  Corr_data$EMK_EM_Ch = qn_data$EMK_EM_Ch

# Compute composite scores for parental/children measures of EMK
  Corr_data$EMK_EK = scale(Corr_data$EMK_EK_P) + scale(Corr_data$EMK_EK_Ch)
  Corr_data$EMK_EM = scale(Corr_data$EMK_EM_P) + scale(Corr_data$EMK_EM_Ch)

# Select variables
  ERPs_corr_F2 = subset(Corr_data,select = c(P1_F2_Nov_Rep_Hap, P1_F2_Nov_Hap_Ang, EMK_EK_P, EMK_EK_Ch,
                                             EMK_EM_P, EMK_EM_Ch)) 

  
```

**Correlation of EMK empathy composite scores with significant P1 amplitude repetition x emotion interactions**

```{r Corr_calc_EMK_EM, results = "asis"}

# Calculate EMK Empathy associations with significant P1 repetition x emotion interaction 
  EMK_EM_Nov_Hap_Rep_Hap = cor.test(Corr_data$P1_F2_Nov_Rep_Hap, Corr_data$EMK_EM)
  EMK_EM_Nov_Hap_Nov_Ang = cor.test(Corr_data$P1_F2_Nov_Hap_Ang, Corr_data$EMK_EM)

# Merge table 
  P1_Corr_Nov_Hap_Rep_Hap = c(EMK_EM_Nov_Hap_Rep_Hap$estimate[[1]], EMK_EM_Nov_Hap_Rep_Hap$conf.int[1], EMK_EM_Nov_Hap_Rep_Hap$conf.int[2],
                            EMK_EM_Nov_Hap_Rep_Hap$statistic[[1]], EMK_EM_Nov_Hap_Rep_Hap$p.value)
  
  P1_Corr_Nov_Hap_Nov_Ang = c(EMK_EM_Nov_Hap_Nov_Ang$estimate[[1]], EMK_EM_Nov_Hap_Nov_Ang$conf.int[1], EMK_EM_Nov_Hap_Nov_Ang$conf.int[2],
                            EMK_EM_Nov_Hap_Nov_Ang$statistic[[1]], EMK_EM_Nov_Hap_Nov_Ang$p.value)
  
  EMK_EM_table = as.data.frame(rbind(P1_Corr_Nov_Hap_Rep_Hap, P1_Corr_Nov_Hap_Nov_Ang))

# Rename columns
  names(EMK_EM_table)[1] = "r"
  names(EMK_EM_table)[2] = "Upper CI"
  names(EMK_EM_table)[3] = "Lower CI"
  names(EMK_EM_table)[4] = "t"
  names(EMK_EM_table)[5] = "p (uncorrected)"
  
# Print table 
  kable(EMK_EM_table) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
  
# For supplement: mean / SD  
  #mean(Corr_data$EMK_EM)
  #SD(Corr_data$EMK_EM)
  
  #mean(Corr_data$EMK_EK)
  #SD(Corr_data$EMK_EK)
  
  #mean(Corr_data$P1_F2_Nov_Rep_Hap, na.rm = TRUE)
  #SD(Corr_data$P1_F2_Nov_Rep_Hap)
  
  #mean(Corr_data$P1_F2_Nov_Hap_Ang, na.rm = TRUE)
  #SD(Corr_data$P1_F2_Nov_Hap_Ang)

```

**Correlation of EMK emotion knowledge composite scores with significant P1 amplitude repetition x emotion interactions**

```{r Corr_calc_EMK_EK, results = "asis"}

# Calculate EMK Empathy associations with significant P1 repetition x emotion interaction 
  EMK_EK_Nov_Hap_Rep_Hap = cor.test(Corr_data$P1_F2_Nov_Rep_Hap, Corr_data$EMK_EK)
  EMK_EK_Nov_Hap_Nov_Ang = cor.test(Corr_data$P1_F2_Nov_Hap_Ang, Corr_data$EMK_EK)

# Merge table 
  P1_Corr_Nov_Hap_Rep_Hap = c(EMK_EK_Nov_Hap_Rep_Hap$estimate[[1]], EMK_EK_Nov_Hap_Rep_Hap$conf.int[1], EMK_EK_Nov_Hap_Rep_Hap$conf.int[2],
                            EMK_EK_Nov_Hap_Rep_Hap$statistic[[1]], EMK_EK_Nov_Hap_Rep_Hap$p.value)
  
  P1_Corr_Nov_Hap_Nov_Ang = c(EMK_EK_Nov_Hap_Nov_Ang$estimate[[1]], EMK_EK_Nov_Hap_Nov_Ang$conf.int[1], EMK_EK_Nov_Hap_Nov_Ang$conf.int[2],
                            EMK_EK_Nov_Hap_Nov_Ang$statistic[[1]], EMK_EK_Nov_Hap_Nov_Ang$p.value)
  
  EMK_EK_table = as.data.frame(rbind(P1_Corr_Nov_Hap_Rep_Hap, P1_Corr_Nov_Hap_Nov_Ang))

# Rename columns
  names(EMK_EK_table)[1] = "r"
  names(EMK_EK_table)[2] = "Upper CI"
  names(EMK_EK_table)[3] = "Lower CI"
  names(EMK_EK_table)[4] = "t"
  names(EMK_EK_table)[5] = "p (uncorrected)"
  
# Print table 
  kable(EMK_EK_table) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
  
```

We calculated difference scores of significant emotion x repetition interactions (novel happy-repeated happy, novel happy-novel angry) for P1 amplitudes. Subsequently, we associated them with EMK 3-6 empathy and emotion knowledge composite scores. None of the correlations of emotion knowledge or empathy with P1 difference scores survived FDR-correction (all *p* > .63)

```{r save_corr_results, include = FALSE, eval = FALSE}

# Save data set in RData format
  save(ERPs_corr_F2, file = "./data/ERPs_corr_F2.RData")
  save(Corr_data, file = "./data/Corr_data.RData")

```

<br>

# Session info

<!-- Provide session info  -->

```{r session_info, results = TRUE}

# Get session info 
  sessionInfo()

```
