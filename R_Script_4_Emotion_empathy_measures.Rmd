---
title: "Emotion and empathy measures"
output: 
  rmdformats::material:
    highlight: kate
    css: web_style.css
    thumbnails: false
    lightbox: true
    gallery: true
    cards: true
    self_contained: no
    number_sections: no
    code_folding: hide
    fig_caption: yes
---

<!-- Set up workspace -->

```{r setup, include = FALSE, message = FALSE, warning = FALSE}

# Set general settings for Markdown file 
  options(max.print="75")

  knitr::opts_chunk$set(echo=TRUE,
  	             #cache=TRUE,
                 prompt=FALSE,
                 tidy=TRUE,
                 comment=NA,
                 message=FALSE,
                 warning=FALSE,
                 results = FALSE,
  	             fig.align="center",
  	             fig.width = 6, fig.height = 4)
  knitr::opts_knit$set(width=75)

# Swipe environment
  #rm(list=ls())
  
# Load packages
  library(apaTables)
  library(corrplot)
  library(cowplot)
  library(dplyr)
  library(eeptools)
  library(EnvStats)
  library(ez)
  library(ggplot2)
  library(ggstatsplot)
  library(gridGraphics)
  library(gvlma)
  library(Hmisc)
  library(knitr)
  library(lme4)
  library(lmerTest)
  library(MASS)
  library(miceadds)
  library(pander)
  library(psych)
  library(reshape2)
  library(Rmisc)
  library(sjPlot)
  library(sjmisc)
  library(sjlabelled)
  library(stringr)
  library(table1)
  library(tidyverse)

# Raincloud plot function   
  source("./functions/geom_flat_violin.R")
    
# Load overdispersion function
  overdisp_fun = function(model) {
      rdf = df.residual(model)
      rp = residuals(model,type="pearson")
      Pearson.chisq = sum(rp^2)
      prat = Pearson.chisq/rdf
      pval = pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
      c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
  }
  
# Load correlation table function (https://stefaneng.github.io/apa_correlation_table/)
 apply_if <- function(mat, p, f) {
  # Fill NA with FALSE
  p[is.na(p)] <- FALSE
  mat[p] <- f(mat[p])
  mat
}


apaCorr <- function(mat, corrtype = "spearman") {
  matCorr <- mat
  if (class(matCorr) != "rcorr") {
    matCorr <- rcorr(mat, type = corrtype)
  }

  # Add one star for each p < 0.05, 0.01, 0.001
  stars <- apply_if(round(matCorr$r, 2), matCorr$P < 0.05, function(x) paste0(x, "*"))
  stars <- apply_if(stars, matCorr$P < 0.01, function(x) paste0(x, "**"))
  stars <- apply_if(stars, matCorr$P < 0.001, function(x) paste0(x, "***"))
  # Put - on diagonal and blank on upper diagonal
  stars[upper.tri(stars, diag = T)] <- "-"
  stars[upper.tri(stars, diag = F)] <- ""
  n <- length(stars[1,])
  colnames(stars) <- 1:n
  # Remove _ and convert to title case
  row.names(stars) <- tools::toTitleCase(sapply(row.names(stars), gsub, pattern="_", replacement = " "))
  # Add index number to row names
  row.names(stars) <- paste(paste0(1:n,"."), row.names(stars))
  stars
}
  
# Round to 2 digits   
  options(digits=2)
  
# Disable scientific notation in R
  options(scipen = 999)
  
# Set figure theme  
  theme_SN = theme(axis.title.y = element_text(size = 15, margin = margin(t = 0, r = 20, b = 0, l = 0)),
          panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(),
          panel.grid.major.y = element_line(colour = "black", linetype = "dotted", size=0.6),
          panel.grid.minor.y = element_blank(),
          panel.background = element_rect(colour = "black", size = 0.5),
          text=element_text(size = 15),
          legend.position = "none")  
  
# Set figure color palettes
  emotion_col = c("#99bada","#3375b5","#003162")
  
# Mean-center function
  center_scale <- function(x) {
    scale(x, scale = FALSE)}  
  
```

<!-- Load and prepare data sets -->

```{r load_data, include = FALSE}

# Load data
  load.Rdata(filename="./data/EMT_data.Rdata", "EMT")
  load.Rdata(filename="./data/ERP_data.Rdata", "ERPs")
  load.Rdata(filename="./data/qn_data.Rdata", "qn_data")

```

# Emotion matching task

We employed an emotion matching task (EMT; adapted from Watling & Damaskinou, 2018) to assess children's emotion knowledge. Children saw two faces with the same identity but different facial expression. Both faces were presented at the same time. While the faces were on screen, the children heard an audio lay-over of one of the emotion words (happy, angry or neutral). The children had to indicate with a button press which face matched the audio lay-over. We measured reaction times and accuracy.  

We excluded: 

  + Reaction times < 250 ms or >  7s
  + Values </> 2.5 of the median absolute deviation (MAD) based on the individual participant
  + Incorrect answers
  
We calculated general linear mixed models (GLMM) for accuracy rates and linear mixed models (LMM) for reaction times. Fixed effects are defined for each model individually. Chronological age and working memory were entered as scaled covariates in all (general) linear mixed model analyses to control for cognitive abilities of the children as well as potential differences in age.

The random effects structure included random intercepts for participants `(1|ID)` and stimulus `(1|Stim_Type)`. For each model, we commenced with the maximal random effect structure. Random intercepts were defined for participants and stimuli. Random slopes were defined for all predictors, but not covariates. We set correlations of random terms to zero and performed a principal component analysis on the random-effects variance-covariance estimates to determine the number of components supported by the data. We removed random effects explaining zero variance, in order to prevent over-parametrization. Afterwards, we checked whether all random intercepts improved the model using likelihood-ratio-testing.

We expected the highest accuracy rates for happy faces (tested with `GLMM`) and fastest reaction times for pairings where happy faces were involved (tested with `LMM`). Assumptions for multiple regression were checked for all models (normality of the residuals, linearity, multicollinearity, homoscedasticity). 

<br>

#### **Descriptives**

<br>

<!-- Plot EMT accuracy & reaction time -->

```{r EMT_acc_RT_plot, fig.width = 8, fig.height = 4}

# Select RT inspected criteria
  EMT_Acc_Plot = subset(EMT,Exclude_smaller_250ms == FALSE & Exclude_larger_7s == FALSE & Exclude_MAD == FALSE) 

# Select correct trials
  EMT_Acc_Plot = subset(EMT_Acc_Plot, Answer == 1)

# Create factor, define neutral as baseline
  EMT_Acc_Plot$emotion = factor(EMT_Acc_Plot$emotion, levels=c("neutral","happy","angry"))

# Get accuracy for novel and repeated condition 
  acc_all = data.frame(xtabs(~ID+emotion, EMT_Acc_Plot)) 

# Recode to accuracy in percent
  acc_all$Freq = (acc_all$Freq/24)*100
  
# Set ID as factor  
  acc_all$ID = as.factor(acc_all$ID)

# Calculate descriptives on accuracy
  stats_acc_all = summarySEwithin(acc_all, measurevar="Freq", withinvars=c("emotion"), idvar = "ID")

# Plot accuracy
  EMT_Acc_bar = ggplot(stats_acc_all, aes(x=emotion, y=Freq, fill = emotion)) + 
    geom_bar(position=position_dodge(), stat="identity",colour="black", size=0.7,width=0.9) +
    geom_errorbar(aes(ymin=Freq-se, ymax=Freq+se), size=1, width=0.2, position=position_dodge(.9)) +
    labs (x= "", y = "Accuracy [%]") +
    coord_cartesian(ylim = c(0, 60)) +
    scale_y_continuous(breaks=seq(0,60,20))+
    scale_fill_manual(values=emotion_col)+
    theme_bw()+
    theme_SN
  
# Only examine clean data
  EMT_RT_Plot = subset(EMT,Exclude_smaller_250ms == FALSE & Exclude_larger_7s == FALSE & Exclude_MAD == FALSE)

# Select correct responses
  EMT_RT_Plot = subset(EMT_RT_Plot, Answer == 1)

# Create factor, define neutral as baseline
  EMT_RT_Plot$emotion = factor(EMT_RT_Plot$emotion, levels=c("neutral","happy","angry"))

# Get accuracy for novel and repeated condition 
  RT_all = aggregate(EMT_RT_Plot$RT_in_ms,
               list(ID = EMT_RT_Plot$ID, emotion = EMT_RT_Plot$emotion), mean)
  
# Set ID as factor  
  RT_all$ID = as.factor(RT_all$ID)  

# Calculate descriptives on RT
  stats_RT_all = summarySEwithin(RT_all, measurevar="x", withinvars=c("emotion"), idvar = "ID")

# Plot RTs
  EMT_RT_bar = ggplot(stats_RT_all, aes(x=emotion, y=x, fill = emotion)) + 
    geom_bar(position=position_dodge(), stat="identity",colour="black", size=0.7,width=0.9) +
    geom_errorbar(aes(ymin=x-se, ymax=x+se), size=1, width=0.2, position=position_dodge(.9)) +
    labs (x= "", y = "RT [ms]") +
    coord_cartesian(ylim = c(0, 3500)) +
    scale_y_continuous(breaks=seq(0,4000,1000))+
    scale_fill_manual(values=emotion_col)+
    theme_bw()+
    theme_SN

# Raincloud plot EMT RT

# # Only examine clean data
#   EMT_RT_Plot = subset(EMT,Exclude_smaller_250ms == FALSE & Exclude_larger_7s == FALSE & Exclude_MAD == FALSE)
# 
# # Select correct responses
#   EMT_RT_Plot = subset(EMT_RT_Plot, Answer == 1)
# 
# # Create factor, define neutral as baseline
#   EMT_RT_Plot$emotion = factor(EMT_RT_Plot$emotion, levels=c("neutral","happy","angry"))
# 
# # Calculate summary
#   lb = function(x) mean(x) - sd(x)
#   ub = function(x) mean(x) + sd(x)
#   
#   sumld = ddply(EMT_RT_Plot , ~ emotion, summarise,
#                 mean = mean(RT_in_ms), median = median(RT_in_ms), lower = lb(RT_in_ms), upper = ub(RT_in_ms))
#   
# # Plot rainclouds
#   EMT_RT_rain =  ggplot(data = EMT_RT_Plot, aes(y = RT_in_ms, x = emotion, fill = emotion))  +
#     geom_flat_violin(position = position_nudge(x = .12, y = 0), alpha = 1, color="black") +
#     geom_point(aes(y = RT_in_ms, color = emotion), shape = 19, position = position_jitter(width = .1), size = .7, alpha = 1)  +
#     geom_point(data = sumld, aes(x = emotion, y = mean), position = position_nudge(x = .2), size = 2.5) +
#     geom_errorbar(data = sumld, aes(ymin = lower, ymax = upper, y = mean), position = position_nudge(x = .2, y = 0), width = 0)+
#     scale_y_continuous(name="Reaction time [ms]", breaks=seq(0,6500,2000), limits=c(0,6500))+
#     xlab("")+
#     expand_limits(x = 2.00) +
#     guides(fill = FALSE) +
#     guides(color = FALSE) +
#     coord_flip() + # flip or not?
#     scale_fill_manual(values=emotion_col) +
#     scale_color_manual(values=emotion_col)+
#     theme_bw() +
#     theme_SN+
#     theme(panel.grid.major.y = element_blank())
  
# Combine plots
  combine_plots(EMT_Acc_bar, EMT_RT_bar,
                ncol = 2, nrow = 1,
                labels = c("A", "B"))

```

<br>

---

#### **Model specification** {.tabset .tabset-pills}

<!-- GLMM / LMM assumption checks -->

##### GLMM: Random effect structure

```{r EMT_Acc_GLMM_res}

# RT cleaning criteria
  EMT_Acc = subset(EMT,Exclude_smaller_250ms == FALSE & Exclude_larger_7s == FALSE & Exclude_MAD == FALSE)  

# Factor random effects 
  EMT_Acc$ID = as.factor(EMT_Acc$ID)
  EMT_Acc$Stim_Type = as.factor(EMT_Acc$Stim_Type)

# Create factor, define neutral as baseline
  EMT_Acc$emotion = factor(EMT_Acc$emotion, levels=c("neutral","happy","angry"))

# Set treatment contrast
  contrasts(EMT_Acc$emotion) = contr.treatment(3)

# Add contrast columns
  mm_mod_EMT_Acc =  model.matrix( ~ emotion, EMT_Acc) 

# Attach to dataframe
  EMT_Acc[,(ncol(EMT_Acc)+1):(ncol(EMT_Acc)+3)] = mm_mod_EMT_Acc
  names(EMT_Acc)[(ncol(EMT_Acc)-2):ncol(EMT_Acc)] = c("Mean","Hap_Neu", "Ang_Neu") 

# Construct model             
  mod_EMT_Acc.glmm1 = glmer(Answer~ Hap_Neu + Ang_Neu  + scale(Age) + scale(WM) + 
                            (1 + Hap_Neu + Ang_Neu ||ID) + 
                            (1 + Hap_Neu + Ang_Neu ||Stim_Type),                   
                          data = EMT_Acc,control=glmerControl(calc.derivs = FALSE),
                          family = binomial)         


# 1st: check how many zero variance terms you got in random effects
  summary(rePCA(mod_EMT_Acc.glmm1))

# 2nd: check which random terms explain the least variance
  print(VarCorr(mod_EMT_Acc.glmm1),comp = "Variance")

# Likelihood ratio testing 

# ID
  mod_EMT_Acc.glmm2 = glmer(Answer~ Hap_Neu + Ang_Neu  + scale(Age) + scale(WM) + 
                            (1 |ID) + 
                            (1 + Hap_Neu + Ang_Neu ||Stim_Type),                   
                          data = EMT_Acc,control=glmerControl(calc.derivs = FALSE),
                          family = binomial)    

# Calculate ANOVA
  anova(mod_EMT_Acc.glmm1,mod_EMT_Acc.glmm2)


# Stimulus type 
  mod_EMT_Acc.glmm3 = glmer(Answer~ Hap_Neu + Ang_Neu  + scale(Age) + scale(WM) + 
                            (1  + Hap_Neu + Ang_Neu ||ID) + 
                            (1 |Stim_Type),                   
                          data = EMT_Acc,control=glmerControl(calc.derivs = FALSE),
                          family = binomial)    


# Calculate ANOVAs
  anova(mod_EMT_Acc.glmm1,mod_EMT_Acc.glmm3)


# Final model
  mod_EMT_Acc.glmm4 = glmer(Answer~ Hap_Neu + Ang_Neu  + scale(Age) + scale(WM) + (1|ID)+(1 + Hap_Neu + Ang_Neu || Stim_Type),                   
                            data = EMT_Acc,control=glmerControl(calc.derivs = FALSE), family = binomial)  

```

We applied a treatment contrast comparing neutral vs happy and neutral vs angry emotional facial expressions (`Hap_Neu`, `Ang_Neu`). Accordingly, we fitted single-trial data to the following model:


 ``r format(formula(mod_EMT_Acc.glmm4))``

---

##### GLMM: Overdispersion

If the p-value is < 0.05, data would be overdispersed. Here p > 0.05. Hence, overdispersion is not a problem.

```{r EMT_Acc_GLMM_overd, results = TRUE}

# Assumption check: Appropriate estimation of variance
  overdisp_fun(mod_EMT_Acc.glmm4)

```

---

##### LMM: Random effect structure

```{r EMT_RT_LMM_build_mod}
  
# Correct responses
  EMT_RT = subset(EMT, Answer == 1)

# RT cleaning criteria
  EMT_RT = subset(EMT_RT,Exclude_smaller_250ms == FALSE & Exclude_larger_7s == FALSE & Exclude_MAD == FALSE)  

# Factor random effects 
  EMT_RT$ID = as.factor(EMT_RT$ID)
  EMT_RT$Stim_Type = as.factor(EMT_RT$Stim_Type)

# Create factor, define neutral as baseline
  EMT_RT$emotion = factor(EMT_RT$emotion, levels=c("neutral","happy","angry"))

# Set treatment contrast
  contrasts(EMT_RT$emotion) = contr.treatment(3)

# Add contrast columns
  mm_c =  model.matrix( ~ emotion, EMT_RT) 

# Attach to dataframe
  EMT_RT[,(ncol(EMT_RT)+1):(ncol(EMT_RT)+3)] = mm_c
  names(EMT_RT)[(ncol(EMT_RT)-2):ncol(EMT_RT)] =  c("Mean","Hap_Neu", "Ang_Neu") 

# Build model 
  mod_EMT_RT.lmer1 = lmer(log(RT_in_ms) ~ 
                            Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                            (1 + Hap_Neu + Ang_Neu||ID) +
                            (1 + Hap_Neu + Ang_Neu||Stim_Type),
                          data = EMT_RT,
                          control=lmerControl(calc.derivs = FALSE))

# 1st: check how many zero variance terms you got in random effects
  summary(rePCA(mod_EMT_RT.lmer1))

# 2nd: check which random terms explain the least variance
  print(VarCorr(mod_EMT_RT.lmer1),comp = "Variance")


# Improved model
  mod_EMT_RT.lmer2 = lmer(log(RT_in_ms) ~ 
                            Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                            (1 + Ang_Neu||ID) +
                            (0 + Ang_Neu||Stim_Type),
                          data = EMT_RT,
                          control=lmerControl(calc.derivs = FALSE))


# Re-check the model
  summary(rePCA(mod_EMT_RT.lmer2))
  print(VarCorr(mod_EMT_RT.lmer2 ),comp = "Variance")

## Likelihood ratio testing

# ID
  mod_EMT_RT.lmer3 = lmer(log(RT_in_ms) ~ 
                            Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                            (1 |ID) +
                            (0 + Ang_Neu||Stim_Type),
                          data = EMT_RT,
                          control=lmerControl(calc.derivs = FALSE))

# Calculate ANOVA
  anova(mod_EMT_RT.lmer2,mod_EMT_RT.lmer3)

# Stim_Type 
  mod_EMT_RT.lmer4 = lmer(log(RT_in_ms) ~ 
                            Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                            (1 + Ang_Neu|ID) +
                            (1|Stim_Type),
                          data = EMT_RT,
                          control=lmerControl(calc.derivs = FALSE))

# Calculate ANOVA
  anova(mod_EMT_RT.lmer2,mod_EMT_RT.lmer4)


# Final model
  mod_EMT_RT.lmer5 = lmer(log(RT_in_ms) ~ 
                            Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                            (1 | ID)+
                            (1 | Stim_Type),
                          data = EMT_RT,
                          control=lmerControl(calc.derivs = FALSE))
```

We applied a treatment contrast comparing neutral vs happy and neutral vs angry emotional facial expressions (` Neutral vs Happy`, `Neutral vs Angry`). Accordingly, we fitted single-trial data to the following model:

 ``r format(formula(mod_EMT_RT.lmer5))``


---

##### LMM: Normality of residuals

RTs were log-transformed (determined using the Box-Cox procedure) to meet the assumption of normally distributed residuals.

```{r EMT_RT_LMM_res, fig.width = 6, fig.asp = .62}

# Visualize normality assumption of residuals (without log transform)
  mod_RT_lmm_no_log = lm(RT_in_ms ~ emotion, data=EMT_RT)
  res.mod_RT_lmm_no_log = residuals(mod_RT_lmm_no_log)
  
  par(mfrow=c(1,2))
  
  
  qqpl_RT_lmm_no_log = qqPlot(res.mod_RT_lmm_no_log, main="QQplot before transformation")    
  norm_RT_lmm_no_log = plot(density(res.mod_RT_lmm_no_log), main="Density plot before transformation")  
  par(mfrow=c(1,1))

# Check which transformation of DV is suitable

# Calculate box-cox plot
  mod_RT_targ = lm(RT_in_ms ~ emotion, data=EMT_RT)
  boxcox(mod_RT_targ)   

# Visualize normality assumption of residuals (with log transform)
  mod_RT_lmm_log = lm(log(RT_in_ms) ~ emotion, data=EMT_RT)
  res.mod_RT_lmm_log = residuals(mod_RT_lmm_log)
  
  par(mfrow=c(1,2))
  qqpl_RT_lmm_log = qqPlot(res.mod_RT_lmm_log, main="QQplot after transformation")    
  norm_RT_lmm_log = plot(density(res.mod_RT_lmm_log), main="Density plot after transformation")  
  par(mfrow=c(1,1))            
            
```
---

##### LMM: Homoscedasticity

```{r EMT_RT_LMM_homosk, fig.width = 5, fig.asp = .62}

# Check homoscedasticity  
  plot(fitted(mod_EMT_RT.lmer5), residuals(mod_EMT_RT.lmer5))
  abline(0, 0)         
        
```

---

#### **Results**

<!-- Print GLMM / LMM results -->

With regard to accuracy, we did not find a significant effect for happy vs. neutral faces or angry vs. neutral faces. Children were significantly faster for happy compared to neutral faces, but not for angry compared to neutral faces. None of the covariates reached significance.

<div align="center">

```{r EMT_result_table, results = TRUE}
 
# Define labels      
  labels = c("Intercept","Happy vs Neutral", "Angry vs Neutral", "Age","Working memory")

# Show results
  tab_model(mod_EMT_Acc.glmm4, mod_EMT_RT.lmer5,
          pred.labels=labels, show.ci = FALSE,
          show.se = TRUE, string.se = "SE",
          show.stat = TRUE, string.stat = "t",
          show.re.var = TRUE, show.obs = FALSE,
          emph.p = TRUE, dv.labels=c("Accuracy","Reaction time") , show.icc = TRUE)
  
```

</div>

<br>

*Note:* p-values for the fixed effects calculated using Wald-statistics approximation, uncorrected. *SE*: standard error; *t*: test statistic coefficient; *p*: p-value; *σ2*: within-group variance; *τ00*: between-group variance; *ICC*: interclass correlation (ratio of between-cluster variance to total variance); *N*: number of random effects. 

# Emotion- and empathy related measures and ERP

We performed correlational analyses using Pearson\'s correlations (corrected for multiple comparisons using the false discovery rate) to associate behavior and brain variables. We calculated difference scores between P1/P3 amplitudes to angry vs. neutral facial expressions. Subsequently, we performed correlational analysis with the empathy (EM) and emotion knowledge (EK) composite scores of the EMK 3-6. 

<!-- Display correlation plots -->

```{r EMK_ERP_scat_plots}

## Separate data set for neutral and angry and calculate participant's P1/P3 mean

# angry
  ERPs_ang = subset(ERPs, Condition == 3)
  ERPs_mean = data.frame(tapply(ERPs_ang$mean_ROI_P1,ERPs_ang$ID, mean))
  names(ERPs_mean)[1] = "P1_ang"
  ERPs_mean$P3_ang = tapply(ERPs_ang$mean_ROI_P3,ERPs_ang$ID, mean)

# neutral  
  ERPs_neu = subset(ERPs, Condition == 2)
  ERPs_mean$P1_neu = tapply(ERPs_neu$mean_ROI_P1,ERPs_neu$ID, mean)
  ERPs_mean$P3_neu = tapply(ERPs_neu$mean_ROI_P3,ERPs_neu$ID, mean)
  
# happy  
  ERPs_hap = subset(ERPs, Condition == 1)
  ERPs_mean$P1_hap = tapply(ERPs_hap$mean_ROI_P1,ERPs_hap$ID, mean)
  ERPs_mean$P3_hap = tapply(ERPs_hap$mean_ROI_P3,ERPs_hap$ID, mean)

# Calculate difference score for angry-neutral
  ERPs_mean$P1_Diff_Ang_Neu = ERPs_mean$P1_ang-ERPs_mean$P1_neu
  ERPs_mean$P3_Diff_Ang_Neu = ERPs_mean$P3_ang-ERPs_mean$P3_neu
  ERPs_mean$P1_Diff_Hap_Neu = ERPs_mean$P1_hap-ERPs_mean$P1_neu
  ERPs_mean$P3_Diff_Hap_Neu = ERPs_mean$P3_hap-ERPs_mean$P3_neu

# Remove rows of de-selected participants 
  ERPs_mean = ERPs_mean[-c(4),]  
  
# Order questionnaire data by ID  
  qn_data = qn_data[order(qn_data$ID),]

# Integrate questionnare data   
  ERPs_mean$EMK_EK_P = qn_data$EMK_EK_P
  ERPs_mean$EMK_EM_P = qn_data$EMK_EM_P
  ERPs_mean$EMK_EK_Ch = qn_data$EMK_EK_Ch
  ERPs_mean$EMK_EM_Ch = qn_data$EMK_EM_Ch

# Compute composite scores for parental/children measures of EMK
  ERPs_mean$EMK_EK = scale(ERPs_mean$EMK_EK_P) + scale(ERPs_mean$EMK_EK_Ch)
  ERPs_mean$EMK_EM = scale(ERPs_mean$EMK_EM_P) + scale(ERPs_mean$EMK_EM_Ch)

# Select variables
  ERPs_corr = subset(ERPs_mean,select = c(P1_Diff_Ang_Neu, P3_Diff_Ang_Neu, EMK_EM,EMK_EK))

## Plot correlations

# Empathy and P1 difference  
  EMK_ERP_scat1 = ggplot(ERPs_mean,aes(x = EMK_EM, y = P1_Diff_Ang_Neu))+
    geom_point(shape = 21, size = 2, color ="gray0", fill = "gray0")+
    geom_smooth(method=lm, color = "black", size = 1)+
    labs(x = "EMK 3-6 (EM)", y = "P1 angry vs. neutral")+
    theme_bw()

# Empathy and P3 difference  
  EMK_ERP_scat2 = ggplot(ERPs_mean,aes(x = EMK_EM, y = P3_Diff_Ang_Neu))+
    geom_point(shape = 21, size = 2, color ="gray27", fill ="gray27")+
    geom_smooth(method=lm, color = "black", size = 1)+
    labs(x = "EMK 3-6 (EM)", y = "P3 angry vs. neutral")+
    theme_bw()

# EK and P1 difference  
  EMK_ERP_scat3 = ggplot(ERPs_mean,aes(x = EMK_EK, y = P1_Diff_Ang_Neu))+
    geom_point(shape = 21, size = 2, color ="gray35", fill = "gray35")+
    geom_smooth(method=lm, color = "black", size = 1)+
    labs(x = "EMK 3-6 (EK)", y = "P1 angry vs. neutral")+
    theme_bw()

# EK and P3 difference  
  EMK_ERP_scat4 = ggplot(ERPs_mean,aes(x = EMK_EK, y = P3_Diff_Ang_Neu))+
    geom_point(shape = 21, size = 2, color ="gray52", fill ="gray52")+
    geom_smooth(method=lm, color = "black", size = 1)+
    labs(x = "EMK 3-6 (EK)", y = "P3 angry vs. neutral")+
    theme_bw()
  
# Combine plots (Explanation: draw_plot(plot, for position: x = 0, y = 0, width = 1, height = 1))
  ggdraw(xlim = c(0, 1), ylim = c(0,1)) +
    draw_plot(EMK_ERP_scat1, 0, 0.5, 0.5, 0.5) +
    draw_plot(EMK_ERP_scat2, 0.5, 0.5, 0.5, 0.5) +
    draw_plot(EMK_ERP_scat3, 0, 0, 0.5, 0.5) +
    draw_plot(EMK_ERP_scat4, 0.5, 0, 0.5, 0.5) 
    
```

<br>

We found a significant correlation between the empathy score and the difference between P1 amplitudes to angry vs. neutral facial expressions, but not for the P3 difference score. None of the correlations between emotion knowledge with P1 or P3 difference scores yielded significant results.

<br>

```{r EMK_ERP_corr_prep, include = FALSE}

# Subset data for empathy and emotion knowledge 
  ERPs_corr_EM = subset(ERPs_corr, select = c(EMK_EM, P1_Diff_Ang_Neu, P3_Diff_Ang_Neu))
  ERPs_corr_EK = subset(ERPs_corr, select = c(EMK_EK, P1_Diff_Ang_Neu, P3_Diff_Ang_Neu))
  
# For saving them in word file
 # apa.cor.table(ERPs_corr_EM, filename="Table_Corr_EM_ERPs.doc", table.number=1))
 # apa.cor.table(ERPs_corr_EK, filename="Table_Corr_EK_ERPs.doc", table.number=2)
  
# Print table in Rmarkdown  
  ERP_corr_table_EM  = corr.test(ERPs_corr_EM, use = "pairwise", method = "pearson", alpha = .05)
  ERP_corr_table_EK  = corr.test(ERPs_corr_EK, use = "pairwise", method = "pearson", alpha = .05)
  
# Re-name columns / rows
  colnames(ERP_corr_table_EM$ci) = c("lower CI","r","upper CI","p")
  colnames(ERP_corr_table_EK$ci) = c("lower CI","r","upper CI","p")

  rownames(ERP_corr_table_EM$ci) = c("EMK 3-6 EM x P1 angry vs. neutral", "EMK 3-6 EM x P3 angry vs. neutral", "P1 angry vs. neutral x P3 angry vs. neutral")
  rownames(ERP_corr_table_EK$ci) = c("EMK 3-6 EK x P1 angry vs. neutral", "EMK 3-6 EK x P3 angry vs. neutral", "P1 angry vs. neutral x P3 angry vs. neutral")

```

```{r EM_ERP_corr_table, results = 'asis'}
# Print table   
  ERP_corr_table_EM$ci %>%
  pander(caption="Correlations between composite EMK 3-6 empathy score with P1 and P3 difference scores to angry vs. neutral faces.")
```

*Note:* Correlation coefficients were computed with Pearson's correlation. EM: Composite score for empathy of the Inventory to survey of emotional competences for three to six-year-olds; CI = confidence interval; * p < .05; ** p < .01; *** p < .001.

```{r EK_ERP_corr_table, results = 'asis'}
# Print table   
  ERP_corr_table_EK$ci %>%
  pander(caption="Correlations between composite EMK 3-6 emotion knowledge score with P1 and P3 difference scores to angry vs. neutral faces.")  
  
```

*Note:* Correlation coefficients were computed with Pearson's correlation. EK: Composite score for emotion knowledge of the Inventory to survey of emotional competences for three to six-year-olds; CI = confidence interval; * p < .05; ** p < .01; *** p < .001.

# Session info

<!-- Provide session info  -->

```{r session_info, results = TRUE}

# Get session info 
  sessionInfo()

```
